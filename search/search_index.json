{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p>fmov is a blazing-fast Python library for rendering videos frame-by-frame using <code>PIL</code> (Pillow), <code>OpenCV</code> or any other image generation tool (that can be converted to a Numpy array). It combines the simplicity of high-level APIs with the performance of low-level tools like FFmpeg \u2014 perfect for generative art, animations, or automated video creation.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Fast: Built on FFmpeg for high-performance rendering.</li> <li>Scalable: No confusing flags or unreadable code.</li> <li>Audio Support: Register sound effects from within your frame function, at any frame or timestamp.</li> <li>Helpful Utilities: Easy time/frame conversions.</li> <li>GPU Acceleration: Optimized commands based on your machine</li> <li>Modern Pythonic API: Functional, frame-driven, and context-free.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install fmov\n</code></pre> <p>You must also have FFmpeg installed on your system and available in your PATH.</p> Installing FFmpeg<pre><code>sudo apt install ffmpeg     # Linux\nbrew install ffmpeg         # MacOS\nchoco install ffmpeg        # Windows\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"hello_world.py<pre><code>from fmov import Video\nfrom PIL import Image, ImageDraw\n\n# using 'with Video() as video' makes rendering simpler, as when the context ends it calls render automatically\nwith Video(path=\"video.mp4\", width=1920, height=1080, fps=60) as video:\n    total_frames = video.time_to_frame(\"10s\") # turns the timestamp \"60s\" into the number of frames in the video\n\n    # create all the frames in the video\n    for i in range(total_frames):\n\n        # PIL stuff, just rendering out the text \"Hello World\"\n        img = Image.new(\"RGB\", (video.width, video.height), \"#000000\")\n        draw = ImageDraw.Draw(img)\n\n        draw.text(\n            (100, video.height // 2),\n            f\"Hello world! This is frame {i}\",\n            fill=\"#ffffff\"\n        )\n\n        video.add(img) # add the frame to the end of the video\n</code></pre>"},{"location":"Creating%20Videos/1video/","title":"Initializing the Video","text":"<p>The core class of the fmov library is the <code>Video</code> class. This is where you define your video, how frames are generated, and how it is rendered.</p> <pre><code>from fmov import Video\n</code></pre>"},{"location":"Creating%20Videos/1video/#creating-the-video","title":"Creating the Video","text":"<p>There are two methods of creating a video. Either creating the video and utilizing it's <code>Context Manager</code> or calling <code>video.render()</code> manually</p> Context ManagerTraditional <pre><code>from fmov import Video\n\nwith Video(\"video.mp4\") as video:\n\n    for frame in total_frames\n        video.add(frame_image)\n</code></pre> <pre><code>from fmov import Video\n\nvideo = Video(\"video.mp4\")\n\nfor frame in total_frames:\n    video.add(frame_image)\n\nvideo.render()\n</code></pre> <p>As you can see, the main difference is in the fact that there is a manual <code>render()</code> call when the video should be written in the Traditional example. There are some cases where it is useful to be able to control when the video renders.</p>"},{"location":"Creating%20Videos/1video/#parameters-of-the-video-class","title":"Parameters of the Video Class","text":"defaults<pre><code>Video(\n    path: str = \"./video.mp4\",\n    width: int = 1920,\n    height: int = 1080,\n    fps: int = 30,\n    gpu: bool = False,\n    audio_bitrate: str = \"192k\",\n    log_duration: bool = True,\n)\n</code></pre>"},{"location":"Creating%20Videos/1video/#path-str","title":"<code>path: str</code>","text":"<p>default is <code>./video.mp4</code></p> <p>This describes where the video will be written to.</p>"},{"location":"Creating%20Videos/1video/#width-int","title":"<code>width: int</code>","text":"<p>default is <code>1920</code></p> <p>This describes the width of the video in pixels.</p>"},{"location":"Creating%20Videos/1video/#height-int","title":"<code>height: int</code>","text":"<p>default is 1080</p> <p>This descibres the height of the video in pixels.</p>"},{"location":"Creating%20Videos/1video/#fps-int","title":"<code>fps: int</code>","text":"<p>default is <code>30</code></p> <p>This describes the frames per second (framerate) of the video.</p>"},{"location":"Creating%20Videos/1video/#gpu-bool","title":"<code>gpu: bool</code>","text":"<p>default is <code>False</code></p> <p>This describes whether <code>fmov</code> will try to find a gpu accelerated <code>vcodec</code>.</p> <p>GPU acceleration doesn't really make a difference, and can actually tend to be slower. The bottleneck for speed is the image generation code, as it is running through python. The CPU based codec <code>libx264</code> is highly optimized and GPU performance is only necessary in some cases</p>"},{"location":"Creating%20Videos/1video/#audio_bitrate-str","title":"<code>audio_bitrate: str</code>","text":"<p>default is <code>192k</code></p> <p>This describes the bitrate of the audio played in the video.</p>"},{"location":"Creating%20Videos/1video/#log_duration-bool","title":"<code>log_duration: bool</code>","text":"<p>default is <code>True</code></p> <p>This describes whether <code>fmov</code> will print out the length it took to render the video. Keep in mind this is just a number after it renders, not a progress bar.</p>"},{"location":"Creating%20Videos/2converters/","title":"Time &amp; Frame Conversions","text":"<p>fmov provides a set of helpful utilities for converting between frames and time units. This makes it easy to synchronize animation, audio, and effects.</p> example<pre><code>video = Video(fps=30)\n\nvideo.time_to_frame(\"2s\") # 60\nvideo.frame_to_seconds(60) # 2\n</code></pre>"},{"location":"Creating%20Videos/2converters/#time_to_frametime-unionstr-int-int","title":"<code>time_to_frame(time: Union(str | int)) -&gt; int</code>","text":"<p>Returns the frames for a given time code</p> Time Codes<pre><code>video = Video(fps=30)\n\nvideo.time_to_frame(\"1m\") # 1800\nvideo.time_to_frame(\"1m 30s\") # 2700\nvideo.time_to_frame(\"3h 10m 25s 500ms\") # 342765\nvideo.time_to_frame(10) # 10\n</code></pre>"},{"location":"Creating%20Videos/2converters/#frame_to_millisecondsframe-int-int","title":"<code>frame_to_milliseconds(frame: int) -&gt; int</code>","text":"<p>Returns the time in milliseconds that the given frame will begin.</p>"},{"location":"Creating%20Videos/2converters/#frame_to_secondsframe-int-float","title":"<code>frame_to_seconds(frame: int) -&gt; float</code>","text":"<p>Returns the time in seconds that the given frame will begin.</p>"},{"location":"Creating%20Videos/2converters/#frame_to_minutesframe-int-float","title":"<code>frame_to_minutes(frame: int) -&gt; float</code>","text":"<p>Returns the time in minutes that the given frame will begin.</p>"},{"location":"Creating%20Videos/3audio/","title":"Adding Audio","text":"<p>You can add audio events from within your frame function using the <code>video.audio(path, at, volume)</code> method. This allows you to register sound effects at any frame or timestamp, making it easy to synchronize audio with animation events.</p> Audios<pre><code>video.audio(\"./pop.wav\", \"1s\")     # add sound at 1 second\n\nvideo.audio(\"./click.mp3\", 120)    # add sound at 120th frame\n\nvideo.audio(\"./chime.m4a\", \"3m\")   # add sound at 3 minutes\n\nvideo.audio(\"./chime.m4a\", \"3m\", 0.25)   # add sound at half volume\n</code></pre>"},{"location":"Creating%20Videos/3audio/#audiopath-str-at-unionstr-int-volume-float-05","title":"<code>audio(path: str, at: Union(str | int), volume: float: 0.5)</code>","text":"<p>Puts a sound at a given time code. </p> <p>To understand how time codes are evaluated, see Converters.</p> <p>1.0 volume is often too loud for most applications, hence why the default volume is 0.5</p>"},{"location":"Creating%20Videos/3audio/#get_audio_stamps-listaudio","title":"<code>get_audio_stamps() -&gt; list[Audio]</code>","text":"<p>Returns the list of audio stamp objects.</p>"},{"location":"Creating%20Videos/3audio/#audio","title":"<code>Audio</code>","text":"<p>An internal class that can be read when calling <code>get_audio_stamps()</code></p> <p>Contains the attributes <code>time</code> (in frames), <code>path</code>, and <code>volume</code></p>"},{"location":"Creating%20Videos/4other/","title":"Miscellaneous Utilities","text":""},{"location":"Creating%20Videos/4other/#set_pathpath-str-none","title":"<code>set_path(path: str) -&gt; None</code>","text":"<p>Updates the output path for the video file. Useful if you want to change the output location after creating the <code>Video</code> object.</p> example<pre><code>video = Video(path=\"./original.mp4\")\nvideo.set_path(\"./new_output.mp4\")\n</code></pre>"},{"location":"Creating%20Videos/4other/#get_path-str","title":"<code>get_path() -&gt; str</code>","text":"<p>Returns the current output path for the video file.</p> example<pre><code>current_path = video.get_path()\n</code></pre>"},{"location":"Creating%20Videos/4other/#vcodec-dict","title":"<code>vcodec: dict</code>","text":"<p>Every video object has a vcodec block. Parameters such as bitrate, compression, and others can be found inside this object.</p> <p>The contents will be different based on the vcodec selected, although the <code>name</code> key value pair will be present for all vcodecs.</p> <p>The contents of this dictionary may change unless told otherwise</p> <p>vcodec is decided at the creation of the <code>Video</code> object, if changes in available codecs occur this could alter the contents of the dictionary, as they are reliant on the vcodec. If it is necessary, manually set your vcodec with <code>video.set_vcodec</code></p>"},{"location":"Creating%20Videos/4other/#set_vcodecvcodec-str-none","title":"<code>set_vcodec(vcodec: str) -&gt; None</code>","text":"<p>Updates the vcodec manually. See FFmpeg documentation for more on how vcodecs work.</p>"},{"location":"Examples/1start/","title":"Hello World with PIL","text":"main.py<pre><code>from fmov import Video\nfrom PIL import Image, ImageDraw\nfrom tqdm import tqdm\n\n# using 'with Video() as video' makes rendering simpler, as when the context ends it calls render automatically\nwith Video(path=\"video.mp4\", width=1920//4, height=1080//4, fps=60) as video:\n    total_frames = video.time_to_frame(\"20s\") # turns the timestamp \"20s\" into the number of frames in the video\n\n    # create all the frames in the video (tqdm is a progress bar)\n    for i in tqdm(range(total_frames), total=total_frames, desc=\"Rendering\"):\n\n        # PIL stuff, just rendering out the text \"Hello World\"\n        img = Image.new(\"RGB\", (video.width, video.height), \"#000000\")\n        draw = ImageDraw.Draw(img)\n\n        draw.text(\n            (100, video.height // 2),\n            f\"Hello world! This is frame {i}\",\n            fill=\"#ffffff\"\n        )\n\n        video.add(img) # add the frame to the end of the video\n</code></pre> <p>If you would like to see how to make a significantly more performant video, see the OpenCV Example</p> <p>Note</p> <p>For more about how to create frames with PIL, visit the PIL documentation</p>"},{"location":"Examples/2opencv/","title":"Hello World with OpenCV","text":"main.py<pre><code>from fmov import Video\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# using 'with Video() as video' makes rendering simpler, as when the context ends it calls render automatically\nwith Video(path=\"video.mp4\", width=1920, height=1080, fps=60) as video:\n    total_frames = video.time_to_frame(\"20s\") # turns the timestamp \"20s\" into the number of frames in the video\n\n    # create all the frames in the video (tqdm is a progress bar)\n    for i in tqdm(range(total_frames), total=total_frames, desc=\"Rendering\"):\n\n        frame = np.zeros((video.height, video.width, 3), dtype=np.uint8)\n\n        cv2.putText(\n            frame,\n            f\"Hello world! This is frame {i}\",\n            (100, video.height // 2),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            1.5,\n            (255, 255, 255),  # white in BGR\n            2,\n            cv2.LINE_AA\n        )\n\n        # Convert BGR to RGB (because ffmpeg input is rgb24)\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n        video.add(frame) # add the frame to the end of the video\n</code></pre>"},{"location":"Examples/3dvd_bounce/","title":"DVD Bounce Example","text":"main.py<pre><code>from PIL import Image\nimport random\nfrom fmov import Video\nfrom tqdm import tqdm\n\nwith Video(path=\"./video.mp4\", width=1920, height=1080, fps=30) as video:\n    # position and velocity of the dvd logo\n    x,y = (0,0)\n    v = 180//video.fps\n    vx, vy = (v,v)\n\n    total_frames = video.time_to_frame(\"1m\")\n\n    # using rich.track to keep track of the progress, does a good job of predicting ETA usually\n    # keep in mind that this only counts the loading of the video, the audio comes afterward but\n    # usually is negligable unless you have a large file with many effects\n    for i in tqdm(range(total_frames), total=total_frames, \"Rendering...\"):\n        # initializing the common PIL variables\n        image = Image.new(\"RGB\", (video.width, video.height), \"#000000\")\n        #draw = ImageDraw.Draw(image) # usually you need this to draw shapes and text, however this example doesnt require it\n\n        # adding the dvd image\n        # finding the fill color based on the hue, turn it into an image, and use the dvd image as a mask\n        fill_color = Image.new(\"HSV\", (1, 1), (hue, 200, 220)).convert(\"RGB\").getpixel((0, 0))\n        color_layer = Image.new(\"RGB\", dvd_img.size, fill_color)\n        image.paste(color_layer, (x, y), dvd_img.convert(\"L\") if dvd_img.mode != \"RGBA\" else dvd_img.split()[3])\n\n        # collision detection\n        bumped = False\n        if x+vx &gt;= video.width-img_width or x+vx &lt;= 0:\n            vx *= -1\n            bumped = True\n        if y+vy &gt;= video.height-img_height or y+vy &lt;= 0:\n            vy *= -1\n            bumped = True\n\n        # play a sound effect and shift the hue of the logo on a bump\n        if bumped:\n            video.sound(path=\"./audio.wav\", at=i)\n            hue = (hue+random.randint(20,60))%255\n\n        # position updates\n        x += vx\n        y += vy\n\n        # finally, append the frame to the end of the video\n        video.add(image)\n</code></pre>"}]}